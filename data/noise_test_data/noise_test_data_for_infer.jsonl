{"md5": "689a1527123137f9ff72bab1afe3d129_1", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children. Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\n I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level. Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_2", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children. Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]).\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level. Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_3", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children. Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level. Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_4", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children. Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\n the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level. Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_5", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children. Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\n If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level. Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_6", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children. Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\n)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level. Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_7", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\n Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_8", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\n Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_9", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children.\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\n Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_10", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have.\nSpecial characters have evolved over time, influenced by various writing systems and technological advancements in computing.\n In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_11", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers. I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\nSpecial characters, such as those used in programming and design, have become integral to digital communication and interface design.\n\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "689a1527123137f9ff72bab1afe3d129_12", "length": 13917, "question": "Document: LESSWRONG\nCommon sense as a prior\nby Nick_Beckstead26 min read11th Aug 2013215 comments\nAbsurdity HeuristicEpistemology\nAn outline of the framework and some guidelines for applying it effectively\nSome further reasons to think that the framework is likely to be helpful\nCases where people often don't follow the framework but I think they should\nObjections to this approach\nObjection: elite common sense is often wrong\nObjection: the best people are highly unconventional\nObjection: elite common sense is wrong about X, and can't be talked out of it, so your framework should be rejected in general\n[I have edited the introduction of this post for increased clarity.]\nThis post is my attempt to answer the question, \"How should we take account of the distribution of opinion and epistemic standards in the world?\" By \"epistemic standards,\" I roughly mean a person's way of processing evidence to arrive at conclusions. If people were good Bayesians, their epistemic standards would correspond to their fundamental prior probability distributions. At a first pass, my answer to this questions is:\nMain Recommendation: Believe what you think a broad coalition of trustworthy people would believe if they were trying to have accurate views and they had access to your evidence.\nThe rest of the post can be seen as an attempt to spell this out more precisely and to explain, in practical terms, how to follow the recommendation. Note that there are therefore two broad ways to disagree with the post: you might disagree with the main recommendation, or the guidelines for following main recommendation.\nThe rough idea is to try find a group of people whose are trustworthy by clear and generally accepted indicators, and then use an impartial combination of the reasoning standards that they use when they are trying to have accurate views. I call this impartial combination elite common sense. I recommend using elite common sense as a prior in two senses. First, if you have no unusual information about a question, you should start with the same opinions as the broad coalition of trustworthy people would have. But their opinions are not the last word, and as you get more evidence, it can be reasonable to disagree. Second, a complete prior probability distribution specifies, for any possible set of evidence, what posterior probabilities you should have. In this deeper sense, I am not just recommending that you start with the same opinions as elite common sense, but also you update in ways that elite common sense would agree are the right ways to update. In practice, we can't specify the prior probability distribution of elite common sense or calculate the updates, so the framework is most useful from a conceptual perspective. It might also be useful to consider the output of this framework as one model in a larger model combination.\nI am aware of two relatively close intellectual relatives to my framework: what philosophers call \"equal weight\" or \"conciliatory\" views about disagreement and what people on LessWrong may know as \"philosophical majoritarianism.\" Equal weight views roughly hold that when two people who are expected to be roughly equally competent at answering a certain question have different subjective probability distributions over answers to that question, those people should adopt some impartial combination of their subjective probability distributions. Unlike equal weight views in philosophy, my position is meant as a set of rough practical guidelines rather than a set of exceptionless and fundamental rules. I accordingly focus on practical issues for applying the framework effectively and am open to limiting the framework's scope of application. Philosophical majoritarianism is the idea that on most issues, the average opinion of humanity as a whole will be a better guide to the truth than one's own personal judgment. My perspective differs from both equal weight views and philosophical majoritarianism in that it emphasizes an elite subset of the population rather than humanity as a whole and that it emphasizes epistemic standards more than individual opinions. My perspective differs from what you might call \"elite majoritarianism\" in that, according to me, you can disagree with what very trustworthy people think on average if you think that those people would accept your views if they had access to your evidence and were trying to have accurate opinions.\nI am very grateful to Holden Karnofsky and Jonah Sinick for thought-provoking conversations on this topic which led to this post. Many of the ideas ultimately derive from Holden's thinking, but I've developed them, made them somewhat more precise and systematic, discussed additional considerations for and against adopting them, and put everything in my own words. I am also grateful to Luke Muehlhauser and Pablo Stafforini for feedback on this post.\nIn the rest of this post I will:\nOutline the framework and offer guidelines for applying it effectively. I explain why I favor relying on the epistemic standards of people who are trustworthy by clear indicators that many people would accept, why I favor paying more attention to what people think than why they say they think it (on the margin), and why I favor stress-testing critical assumptions by attempting to convince a broad coalition of trustworthy people to accept them.\nOffer some considerations in favor of using the framework.\nRespond to the objection that common sense is often wrong, the objection that the most successful people are very unconventional, and objections of the form \"elite common sense is wrong about X and can't be talked out of it.\"\nDiscuss some limitations of the framework and some areas where it might be further developed. I suspect it is weakest in cases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and cases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nMy suggestion is to use elite common sense as a prior rather than the standards of reasoning that come most naturally to you personally. The three main steps for doing this are:\nTry to find out what people who are trustworthy by clear indicators that many people would accept believe about the issue.\nIdentify the information and analysis you can bring to bear on the issue.\nTry to find out what elite common sense would make of this information and analysis, and adopt a similar perspective.\nOn the first step, people often have an instinctive sense of what others think, though you should beware the false consensus effect. If you don't know what other opinions are out there, you can ask some friends or search the internet. In my experience, regular people often have similar opinions to very smart people on many issues, but are much worse at articulating considerations for and against their views. This may be because many people copy the opinions of the most trustworthy people.\nI favor giving more weight to the opinions of people who can be shown to be trustworthy by clear indicators that many people would accept, rather than people that seem trustworthy to you personally. This guideline is intended to help avoid parochialism and increase self-skepticism. Individual people have a variety of biases and blind spots that are hard for them to recognize. Some of these biases and blind spots—like the ones studied in cognitive science—may affect almost everyone, but others are idiosyncratic—like biases and blind spots we inherit from our families, friends, business networks, schools, political groups, and religious communities. It is plausible that combining independent perspectives can help idiosyncratic errors wash out.\nIn order for the errors to wash out, it is important to rely on the standards of people who are trustworthy by clear indicators that many people would accept rather than the standards of people that seem trustworthy to you personally. Why? The people who seem most impressive to us personally are often people who have similar strengths and weaknesses to ourselves, and similar biases and blind spots. For example, I suspect that academics and people who specialize in using a lot of explicit reasoning have a different set of strengths and weaknesses from people who rely more on implicit reasoning, and people who rely primarily on many weak arguments have a different set of strengths and weaknesses from people who rely more on one relatively strong line of argument.\nSome good indicators of general trustworthiness might include: IQ, business success, academic success, generally respected scientific or other intellectual achievements, wide acceptance as an intellectual authority by certain groups of people, or success in any area where there is intense competition and success is a function of ability to make accurate predictions and good decisions. I am less committed to any particular list of indicators than the general idea.\nOf course, trustworthiness can also be domain-specific. Very often, elite common sense would recommend deferring to the opinions of experts (e.g., listening to what physicists say about physics, what biologists say about biology, and what doctors say about medicine). In other cases, elite common sense may give partial weight to what putative experts say without accepting it all (e.g. economics and psychology). In other cases, they may give less weight to what putative experts say (e.g. sociology and philosophy). Or there may be no putative experts on a question. In cases where elite common sense gives less weight to the opinions of putative experts or there are no plausible candidates for expertise, it becomes more relevant to think about what elite common sense would say about a question.\nHow should we assign weight to different groups of people? Other things being equal, a larger number of people is better, more trustworthy people are better, people who are trustworthy by clearer indicators that more people would accept are better, and a set of criteria which allows you to have some grip on what the people in question think is better, but you have to make trade-offs. If I only included, say, the 20 smartest people I had ever met as judged by me personally, that would probably be too small a number of people, the people would probably have biases and blind spots very similar to mine, and I would miss out on some of the most trustworthy people, but it would be a pretty trustworthy collection of people and I'd have some reasonable sense of what they would say about various issues. If I went with, say, the 10 most-cited people in 10 of the most intellectually credible academic disciplines, 100 of the most generally respected people in business, and the 100 heads of different states, I would have a pretty large number of people and a broad set of people who were very trustworthy by clear standards that many people would accept, but I would have a hard time knowing what they would think about various issues because I haven't interacted with them enough. How these factors can be traded-off against each other in a way that is practically most helpful probably varies substantially from person to person.\nI can't give any very precise answer to the question about whose opinions should be given significant weight, even in my own case. Luckily, I think the output of this framework is usually not very sensitive to how we answer this question, partly because most people would typically defer to other, more trustworthy people. If you want a rough guideline that I think many people who read this post could apply, I would recommend focusing on, say, the opinions of the top 10% of people who got Ivy-League-equivalent educations (note that I didn't get such an education, at least as an undergrad, though I think you should give weight to my opinion; I'm just giving a rough guideline that I think works reasonably well in practice). You might give some additional weight to more accomplished people in cases where you have a grip on how they think.\nI don't have a settled opinion about how to aggregate the opinions of elite common sense. I suspect that taking straight averages gives too much weight to the opinions of cranks and crackpots, so that you may want to remove some outliers or give less weight to them. For the purpose of making decisions, I think that sophisticated voting methods (such as the Condorcet method) and analogues of the parliamentary approaches outlined by Nick Bostrom and Toby Ord seem fairly promising as rough guidelines in the short run. I don't do calculations with this framework—as I said, it's mostly conceptual—so uncertainty about an aggregation procedure hasn't been a major issue for me.\nOn the margin, I favor paying more attention to people's opinions than their explicitly stated reasons for their opinions. Why? One reason is that I believe people can have highly adaptive opinions and patterns of reasoning without being able to articulate good defenses of those opinions and/or patterns of reasoning. (Luke Muehlhauser has discussed some related points here.) One reason is that people can adopt practices that are successful without knowing why they are successful, others who interact with them can adopt those practices, others who interact with them can adopt those practices, and so forth. I heard an extreme example of this from Spencer Greenberg, who had read it in Scientists Greater than Einstein. The story involved a folk remedy for visual impairment:\nThere were folk remedies worthy of study as well. One widely used in Java on children with either night blindness or Bitot's spots consisted of dropping the juices of lightly roasted lamb's liver into the eyes of affected children.\n2. After opening the 'Character Viewer' in MacOSX, select the 'Technical Symbols' category. You will find symbols like ⌘⌃⌥⇧ in this area, which are special characters in MacOSX.\n Sommer relates, \"We were bemused at the appropriateness of this technique and wondered how it could possibly be effective. We, therefore, attended several treatment sessions, which were conducted exactly as the villagers had described, except for one small addition—rather than discarding the remaining organ, they fed it to the affected child. For some unknown reason this was never considered part of the therapy itself.\" Sommer and his associates were bemused, but now understood why the folk remedy had persisted through the centuries. Liver, being the organ where vitamin A is stored in a lamb or any other animal, is the best food to eat to obtain vitamin A. (p. 14)\nAnother striking example is bedtime prayer. In many Christian traditions I am aware of, it is common to pray before going to sleep. And in the tradition I was raised in, the main components of prayer were listing things you were grateful for, asking for forgiveness for all the mistakes you made that day and thinking about what you would do to avoid similar mistakes in the future, and asking God for things. Christians might say the point of this is that it is a duty to God, that repentance is a requirement for entry to heaven, or that asking God for things makes God more likely to intervene and create miracles. However, I think these activities are reasonable for different reasons: gratitude journals are great, reflecting on mistakes is a great way to learn and overcome weaknesses, and it is a good idea to get clear about what you really want out of life in the short-term and the long-term.\nAnother reason I have this view is that if someone has an effective but different intellectual style from you, it's possible that your biases and blind spots will prevent you from appreciating their points that have significant merit. If you partly give weight to opinions independently of how good the arguments seem to you personally, this can be less of an issue for you. Jonah Sinick described a striking reason this might happen in Many Weak Arguments and the Typical Mind:\nWe should pay more attention to people's bottom line than to their stated reasons — If most high functioning people aren't relying heavily on any one of the arguments that they give, if a typical high functioning person responds to a query of the type \"Why do you think X?\" by saying \"I believe X because of argument Y\" we shouldn't conclude that the person believes argument Y with high probability. Rather, we should assume that argument Y is one of many arguments that they believe with low confidence, most of which they're not expressing, and we should focus on their belief in X instead of argument Y. [emphasis his]\nThis idea interacts in a complementary way to Luke Muehlhauser's claim that some people who are not skilled at explicit rationality may be skilled in tacit rationality, allowing them to be successful at making many types of important decisions. If we are interacting with such people, we should give significant weight to their opinions independently of their stated reasons.\nA counterpoint to my claim that, on the margin, we should give more weight to others' conclusions and less to their reasoning is that some very impressive people disagree. For example, Ray Dalio is the founder of Bridgewater, which, at least as of 2011, was the world's largest hedge fund. He explicitly disagrees with my claim:\n\"I stress-tested my opinions by having the smartest people I could find challenge them so I could find out where I was wrong. I never cared much about others' conclusions—only for the reasoning that led to these conclusions. That reasoning had to make sense to me. Through this process, I improved my chances of being right, and I learned a lot from a lot of great people.\" (p. 7 of Principles by Ray Dalio)\nI suspect that getting the reasoning to make sense to him was important because it helped him to get better in touch with elite common sense, and also because reasoning is more important when dealing with very formidable people, as I suspect Dalio did and does. I also think that for the some of the highest functioning people who are most in touch with elite common sense, it may make more sense to give more weight to reasoning than conclusions.\nThe elite common sense framework favors testing unconventional views by seeing if you can convince a broad coalition of impressive people that your views are true. If you can do this, it is often good evidence that your views are supported by elite common sense standards. If you can't, it's often good evidence that your views can't be so supported. Obviously, these are rules of thumb and we should restrict our attention to cases where you are persuading people by rational means, in contrast with using rhetorical techniques that exploit human biases. There are also some interesting cases where, for one reason or another, people are unwilling to hear your case or think about your case rationally, and applying this guideline to these cases is tricky.\nImportantly, I don't think cases where elite common sense is biased are typically an exception to this rule. In my experience, I have very little difficulty convincing people that some genuine bias, such as scope insensitivity, really is biasing their judgment. And if the bias really is critical to the disagreement, I think it will be a case where you can convince elite common sense of your position. Other cases, such as deeply entrenched religious and political views, may be more of an exception, and I will discuss the case of religious views more in a later section.\nThe distinction between convincing and \"beating in an argument\" is important for applying this principle. It is much easier to tell whether you convinced someone than it is to tell whether you beat them in an argument. Often, both parties think they won. In addition, sometimes it is rational not to update much in favor of a view if an advocate for that view beats you in an argument.\nIn support of this claim, consider what would happen if the world's smartest creationist debated some fairly ordinary evolution-believing high school student. The student would be destroyed in argument, but the student should not reject evolution, and I suspect he should hardly update at all. Why not? The student should know that there are people out there in the world who could destroy him on either side of this argument, and his personal ability to respond to arguments is not very relevant. What should be most relevant to this student is the distribution of opinion among people who are most trustworthy, not his personal response to small sample of the available evidence. Even if you genuinely are beating people in arguments, there is a risk that you will be like this creationist debater.\nAn additional consideration is that certain beliefs and practices may be reasonable and adopted for reasons that are not accessible to people who have adopted those beliefs and practices, as illustrated with the examples of the liver ritual and bedtime prayer. You might be able to \"beat\" some Christian in an argument about the merits of bedtime prayer, but praying may still be better than not praying. (I think it would be better still to introduce a different routine that serves similar functions—this is something I have done in my own life—but the Christian may be doing better than you on this issue if you don't have a replacement routine yourself.)\nUnder the elite common sense framework, the question is not \"how reliable is elite common sense?\" but \"how reliable is elite common sense compared to me?\" Suppose I learn that, actually, people are much worse at pricing derivatives than I previously believed. For the sake of argument suppose this was a lesson of the 2008 financial crisis (for the purposes of this argument, it doesn't matter whether this is actually a correct lesson of the crisis). This information does not favor relying more on my own judgment unless I have reason to think that the bias applies less to me than the rest of the derivatives market. By analogy, it is not acceptable to say, \"People are really bad at thinking about philosophy. So I am going to give less weight to their judgments about philosophy (psst…and more weight to my personal hunches and the hunches of people I personally find impressive).\" This is only OK if you have evidence that your personal hunches and the hunches of the people you personally find impressive are better than elite common sense, with respect to philosophy. In contrast, it might be acceptable to say, \"People are very bad at thinking about the consequences of agricultural subsidies in comparison with economists, and most trustworthy people would agree with this if they had my evidence. And I have an unusual amount of information about what economists think. So my opinion gets more weight than elite common sense in this case.\" Whether this ultimately is acceptable to say would depend on how good elites are at thinking about the consequences of agricultural subsidies—I suspect they are actually pretty good at it—but this is isn't relevant to the general point that I'm making. The general point is that this is one potentially correct form of an argument that your opinion is better than the current stance of elite common sense.\nThis is partly a semantic issue, but I count the above example as a case where \"you are more reliable than elite common sense,\" even though, in some sense, you are relying on expert opinion rather than your own. But you have different beliefs about who is a relevant expert or what experts say than common sense does, and in this sense you are relying on your own opinion.\nI favor giving more weight to common sense judgments in cases where people are trying to have accurate views. For example, I think people don't try very hard to have correct political, religious, and philosophical views, but they do try to have correct views about how to do their job properly, how to keep their families happy, and how to impress their friends. In general, I expect people to try to have more accurate views in cases where it is in their present interests to have more accurate views. (A quick reference for this point is here.) This means that I expect them to strive more for accuracy in decision-relevant cases, cases where the cost of being wrong is high, and cases where striving for more accuracy can be expected to yield more accuracy, though not necessarily in cases where the risks and rewards are won't come for a very long time. I suspect this is part of what explains why people can be skilled in tacit rationality but not explicit rationality.\nAs I said above, what's critical is not how reliable elite common sense is but how reliable you are in comparison with elite common sense. So it only makes sense to give more weight to your views when learning that others aren't trying to be correct if you have compelling evidence that you are trying to be correct. Ideally, this evidence would be compelling to a broad class of trustworthy people and not just compelling to you personally.\nIn explaining the framework and outlining guidelines for applying it, I have given some reasons to expect this framework to be helpful. Here are some more weak arguments in favor of my view:\nSome studies I haven't personally reviewed closely claim that combinations of expert forecasts are hard to beat. For instance, a review by (Clemen 1989) found that: \"Considerable literature has accumulated over the years regarding the combination of forecasts. The primary conclusion of this line of research is that forecast accuracy can be substantially improved through the combination of multiple individual forecasts.\" (abstract) And a recent work by the Good Judgment Project found that taking an average individual forecasts and transforming it away from .\n1. To input these characters (⌘⌃⌥⇧⇪) in MacOSX, first open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n5 credence gave the lowest errors of a variety of different methods of aggregating judgments of forecasters (p. 42).\nThere are plausible philosophical considerations suggesting that, absent special evidence, there is no compelling reason to favor your own epistemic standards over the epistemic standards that others use.\nIn practice, we are extremely reliant on conventional wisdom for almost everything we believe that isn't very closely related to our personal experience, and single individuals working in isolation have extremely limited ability to manipulate their environment in comparison with individuals who can build on the insights of others. To see this point, consider that a small group of very intelligent humans detached from all cultures wouldn't have much of an advantage at all over other animal species in competition for resources, but humans are increasingly dominating the biosphere. A great deal of this must be chalked up to cultural accumulation of highly adaptive concepts, ideas, and procedures that no individual could develop on their own. I see trying to rely on elite common sense as highly continuous with this successful endeavor.\nHighly adaptive practices and assumptions are more likely to get copied and spread, and these practices and assumptions often work because they help you to be right. If you use elite common sense as a prior, you'll be more likely to be working with more adaptive practices and assumptions.\nSome successful processes for finding valuable information, such as PageRank and Quora, seem analogous to the framework I have outlined. PageRank is one algorithm that Google uses to decide how high different pages should be in searches, which is implicitly a way of ranking high-quality information. I'm speaking about something I don't know very well, but my rough understanding is that PageRank gives pages more votes when more pages link to them, and votes from a page get more weight if that page itself has a lot of votes. This seems analogous to relying on elite common sense because information sources are favored when they are regarded as high quality by a broad coalition of other information sources. Quora seems analogous because it favors answers to questions that many people regard as good.\nI'm going to go look at the first three questions I can find on Quora. I predict that I would prefer the answers that elite common sense would give to these questions to what ordinary common sense would say, and also that I would prefer elite common sense's answers to these questions to my own except in cases where I have strong inside information/analysis. Results: 1st question: weakly prefer elite common sense, don't have much special information. 2nd question: prefer elite common sense, don't have much special information. 3rd question: prefer elite common sense, don't have much special information. Note that I skipped a question because it was a matter of taste. This went essentially the way I predicted it to go.\nThe type of mathematical considerations underlying Condorcet's Jury Theorem give us some reason to think that combined opinions are often more reliable than individual opinions, even though the assumptions underlying this theorem are far from totally correct.\nThere's a general cluster of social science findings that goes under the heading \"wisdom of crowds\" and suggests that aggregating opinions across people outperforms individual opinions in many contexts.\nSome rough \"marketplace of ideas\" arguments suggest that the best ideas will often become part of elite common sense. When claims are decision-relevant, people pay if they have dumb beliefs and benefit if they have smart beliefs. When claims aren't decision-relevant, people sometimes pay a social cost for saying dumb things and get social benefits for saying things that are smarter, and the people with more information have more incentive to speak. For analogous reasons, when people use and promote epistemic standards that are dumb, they pay costs and when they use and promote epistemic standards that are smart. Obviously there are many other factors, including ones that point in different directions, but there is some kind of positive force here.\nI have seen a variety of cases where I believe people don't follow the principles I advocate. There are certain types of errors that I think many ordinary people make and others that are more common for sophisticated people to make. Most of these boil down to giving too much weight to personal judgments, giving too much weight to people who are impressive to you personally but not impressive by clear and uncontroversial standards, or not putting enough weight on what elite common sense has to say.\nGiving too much weight to the opinions of people like you: People tend to hold religious views and political views that are similar to the views of their parents. Many of these people probably aren't trying to have accurate views. And the situation would be much better if people gave more weight to the aggregated opinion of a broader coalition of perspectives.\nI think a different problem arises in the LessWrong and effective altruism communities. In this case, people are much more reflectively choosing which sets of people to get their beliefs from, and I believe they are getting beliefs from some pretty good people. However, taking an outside perspective, it seems overwhelmingly likely that these communities are subject to their own biases and blind spots, and the people who are most attracted to these communities are most likely to suffer from the same biases and blind spots. I suspect elite common sense would take these communities more seriously than it currently does if it had access to more information about the communities, but I don't think it would take us sufficiently seriously to justify having high confidence in many of our more unusual views.\nBeing overconfident on open questions where we don't have a lot of evidence to work with: In my experience, it is common to give little weight to common sense takes on questions about which there is no generally accepted answer, even when it is impossible to use commonsense reasoning to arrive at conclusions that get broad support. Some less sophisticated people seem to see this as a license to think whatever they want, as Paul Graham has commented in the case of politics and religion. I meet many more sophisticated people with unusual views about big picture philosophical, political, and economic questions in areas where they have very limited inside information and very limited information about the distribution of expert opinion. For example, I have now met a reasonably large number of non-experts who have very confident, detailed, unusual opinions about meta-ethics, libertarianism, and optimal methods of taxation. When I challenge people about this, I usually get some version of \"people are not good at thinking about this question\" but rarely a detailed explanation of why this person in particular is an exception to this generalization (more on this problem below).\nThere's an inverse version of this problem where people try to \"suspend judgment\" on questions where they don't have high-quality evidence, but actually end up taking very unusual stances without adequate justification. For example, I sometimes talk with people who say that improving the very long-term future would be overwhelmingly important if we could do it, but are skeptical about whether we can. In response, I sometimes run arguments of the form:\nIn expectation, it is possible to improve broad feature X of the world (education, governance quality, effectiveness of the scientific community, economic prosperity).\nIf we improve feature X, it will help future people deal with various big challenges and opportunities better in expectation.\nIf people deal with these challenges and opportunities better in expectation, the future will be better in expectation.\nTherefore, it is possible to make the future better in expectation.\nI've presented some preliminary thoughts on related issues here. Some people try to resist this argument on grounds of general skepticism about attempts at improving the world that haven't been documented with high-quality evidence. Peter Hurford's post on \"speculative causes\" is the closest example that I can point to online, though I'm not sure whether he still disagrees with me on this point. I believe that there can be some adjustment in the direction of skepticism in light of arguments that GiveWell has articulated here under \"we are relatively skeptical,\" but I consider rejecting the second premise on these grounds a significant departure from elite common sense. I would have a similar view about anyone who rejected any of the other premises—at least if they rejected them for all values of X—for such reasons. It's not that I think the presumption in favor of elite common sense can't be overcome—I strongly favor thinking about such questions more carefully and am open to changing my mind—it's just that I don't think it can be overcome by these types of skeptical considerations. Why not? These types of considerations seem like they could make the probability distribution over impact on the very long-term narrower, but I don't see how they could put it tightly around zero. And in any case, GiveWell articulates other considerations in that post and other posts which point in favor of less skepticism about the second premise.\nPart of the issue may be confusion about \"rejecting\" a premise and \"suspending judgment.\" In my view, the question is \"What are the expected long-term effects of improving factor X?\" You can try not to think about this question or say \"I don't know,\" but when you make decisions you are implicitly committed to certain ranges of expected values on these questions. To justifiably ignore very long-term considerations, I think you probably need your implicit range to be close to zero. I often see people who say they are \"suspending judgment\" about these issues or who say they \"don't know\" acting as if this ranger were very close to zero. I see this as a very strong, precise claim which is contrary to elite common sense, rather than an open-minded, \"we'll wait until the evidence comes in\" type of view to have. Another way to put it is that my claim that improving some broad factor X has good long-run consequences is much more of an anti-prediction than the claim that its expected effects are close to zero. (Independent point: I think that a more compelling argument than the argument that we can't affect the far future is the argument that that lots of ordinary actions have flow-through effects with astronomical expected impacts if anything does, so that people aiming explicitly at reducing astronomical waste are less privileged than one might think at first glance. I hope to write more about this issue in the future.)\nPutting too much weight on your own opinions because you have better arguments on topics that interest you than other people, or the people you typically talk to: As mentioned above, I believe that some smart people, especially smart people who rely a lot on explicit reasoning, can become very good at developing strong arguments for their opinions without being very good at finding true beliefs. I think that in such instances, these people will generally not be very successful at getting a broad coalition of impressive people to accept their views (except perhaps by relying on non-rational methods of persuasion). Stress-testing your views by trying to actually convince others of your opinions, rather than just out-arguing them, can help you avoid this trap.\nPutting too much weight on the opinions of single individuals who seem trustworthy to you personally but not to people in general, and have very unusual views: I have seen some people update significantly in favor of very unusual philosophical, scientific, and sociological claims when they encounter very intelligent advocates of these views. These people are often familiar with Aumann's agreement theorem and arguments for splitting the difference with epistemic peers, and they are rightly troubled by the fact that someone fairly similar to them disagrees with them on an issue, so they try to correct for their own potential failures of rationality by giving additional weight to the advocates of these very unusual views.\nHowever, I believe that taking disagreement seriously favors giving these very unusual views less weight, not more. The problem partly arises because philosophical discussion of disagreement often focuses on the simple case of two people sharing their evidence and opinions with each other. But what's more relevant is the distribution of quality-weighted opinion around the world in general, not the distribution of quality-weighted opinion of the people that you have had discussions with, and not the distribution of quality-weighted opinion of the people that seem trustworthy to you personally. The epistemically modest move here is to try to stay closer to elite common sense, not to split the difference.\nOne objection I often hear is that elite common sense is often wrong. I believe this is true, but not a problem for my framework. I make the comparative claim that elite common sense is more trustworthy than the idiosyncratic standards of the vast majority of individual people, not the claim that elite common sense is almost always right. A further consideration is that analogous objections to analogous views fail. For instance, \"markets are often wrong in their valuation of assets\" is not a good objection to the efficient markets hypothesis. As explained above, the argument that \"markets are often wrong\" needs to point to specific way in which one can do better than the market in order for it to make sense to place less weight on what the market says than on one's own judgments.\nAnother objection I sometimes hear is that the most successful people often pay the least attention to conventional wisdom. I think this is true, but not a problem for my framework. One reason I believe this is that, according to my framework, when you go against elite common sense, what matters is whether elite common sense reasoning standards would justify your opinion if someone following those standards knew about your background, information, and analysis. Though I can't prove it, I suspect that the most successful people are often depart from elite common sense in ways that elite common sense would endorse if it had access to more information. I also believe that the most successful people tend to pay attention to elite common sense in many areas, and specifically bet against elite common sense in areas where they are most likely to be right.\nA second consideration is that going against elite common sense may be a high-risk strategy, so that it is unsurprising if we see the most successful people pursuing it. People who give less weight to elite common sense are more likely to spend their time on pointless activities, join cults, and become crackpots, though they are also more likely to have revolutionary positive impacts. Consider an analogy: it may be that the gamblers who earned the most used the riskiest strategies, but this is not good evidence that you should use a risky strategy when gambling because the people who lost the most also played risky strategies.\nA third consideration is that while it may be unreasonable to be too much of an independent thinker in a particular case, being an independent thinker helps you develop good epistemic habits. I think this point has a lot of merit, and could help explain why independent thinking is more common among the most successful people. This might seem like a good reason not to pay much attention to elite common sense. However, it seems to me that you can get the best of both worlds by being an independent thinker and keeping separate track of your own impressions and what elite common sense would make of your evidence. Where conflicts come up, you can try to use elite common sense to guide your decisions.\nI feel my view is weakest in cases where there is a strong upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit. Perhaps many crazy-sounding entrepreneurial ideas and scientific hypotheses fit this description. I believe it may make sense to pick a relatively small number of these to bet on, even in cases where you can't convince elite common sense that you are on the right track. But I also believe that in cases where you really do have a great but unconventional idea, it will be possible to convince a reasonable chunk of elite common sense that your idea is worth trying out.\nAnother common objection takes the form: view X is true, but X is not a view which elite common sense would give much weight to. Eliezer makes a related argument here, though he is addressing a different kind of deference to common sense. He points to religious beliefs, beliefs about diet, and the rejection of cryonics as evidence that you shouldn't just follow what the majority believes. My position is closer to \"follow the majority's epistemic standards\" than \"believe what the majority beliefs,\" and closer still to \"follow the best people's epistemic standards without cherry picking \"best\" to suit your biases,\" but objections of this form could have some force against the framework I have defended.\nA first response is that unless one thinks there are many values of X in different areas where my framework fails, providing a few counterexamples is not very strong evidence that the framework isn't helpful in many cases. This is a general issue in philosophy which I think is underappreciated, and I've made related arguments in chapter 2 of my dissertation. I think the most likely outcome of a careful version of this attack on my framework is that we identify some areas where the framework doesn't apply or has to be qualified.\nBut let's delve into the question about religion in greater detail. Yes, having some religious beliefs is generally more popular than being an atheist, and it would be hard to convince intelligent religious people to become atheists. However, my impression is that my framework does not recommend believing in God for the following reasons. Here are a number of weak arguments for this claim:\nMy impression is that the people who are most trustworthy by clear and generally accepted standards are significantly more likely to be atheists than the general population. One illustration of my perspective is that in a 1998 survey of the National Academy of Sciences, only 7% of respondents reported that they believed in God. However, there is a flame war and people have pushed many arguments on this issue, and scientists are probably unrepresentative of many trustworthy people in this respect.\nWhile the world at large has broad agreement that some kind of higher power exists, there is very substantial disagreement about what this means, to the point where it isn't clear that these people are talking about the same thing.\nIn my experience, people generally do not try very hard to have accurate beliefs about religious questions and have little patience for people who want to carefully discuss arguments about religious questions at length. This makes it hard to stress-test one's views about religion by trying to get a broad coalition of impressive people to accept atheism, and makes it possible to give more weight to one's personal take if one has thought unusually carefully about religious questions.\nPeople are generally raised in religious families, and there are substantial social incentives to remain religious. Social incentives for atheists to remain non-religious generally seem weaker, though they can also be substantial. For example, given my current social network, I believe I would pay a significant cost if I wanted to become religious.\nDespite the above point, in my experience, it is much more common for religious people to become atheists than it is for atheists to become religious.\nIn my experience, among people who try very hard to have accurate beliefs about whether God exists, atheism is significantly more common than belief in God.\nIn my experience, the most impressive people who are religious tend not to behave much differently from atheists or have different takes on scientific questions/questions about the future.\nThese points rely a lot on my personal experience, could stand to be researched more carefully, and feel uncomfortably close to lousy contrarian excuses, but I think they are nevertheless suggestive. In light of these points, I think my framework recommends that the vast majority of people with religious beliefs should be substantially less confident in their views, recommends modesty for atheists who haven't tried very hard to be right, and I suspect it allows reasonably high confidence that God doesn't exist for people who have strong indicators that they have thought carefully about the issue. I think it would be better if I saw a clear and principled way for the framework to push more strongly in the direction of atheism, but the case has enough unusual features that I don't see this as a major argument against the general helpfulness of the framework.\nAs a more general point, the framework seems less helpful in the case of religion and politics because people are generally unwilling to carefully consider arguments with the goal of having accurate beliefs. By and large, when people are unwilling to carefully consider arguments with the goal of having accurate beliefs, this is evidence that it is not useful to try to think carefully about this area. This follows from the idea mentioned above that people tend to try to have accurate views when it is in their present interests to have accurate views. So if this is the main way the framework breaks down, then the framework is mostly breaking down in cases where good epistemology is relatively unimportant.\nI've outlined a framework for taking account of the distribution of opinions and epistemic standards in the world and discussed some of its strengths and weaknesses. I think the largest strengths of the framework are that it can help you avoid falling prey to idiosyncratic personal biases, and that using it derives benefits from the \"wisdom of crowds\" effects. The framework is less helpful in:\ncases where there is a large upside to disregarding elite common sense, there is little downside, and you'll find out whether your bet against conventional wisdom was right within a tolerable time limit, and\ncases where people are unwilling to carefully consider arguments with the goal of having accurate beliefs.\nSome questions for people who want to further develop the framework include:\nHow sensitive is the framework to other reasonable choices of standards for selecting trustworthy people? Are there more helpful standards to use?\nHow sensitive is the framework to reasonable choices of standards for aggregating opinions of trustworthy people?\nWhat are the best ways of getting a better grip on elite common sense?\nWhat other areas are there where the framework is particularly weak or particularly strong?\nCan the framework be developed in ways that make it more helpful in cases where it is weakest?\nAbsurdity Heuristic2Epistemology1\n33Is my view contrarian?\n30My daily reflection routine\n9High school activities and medical school admissions\n6Failing to update\n215 comments, sorted by\nHighlighting new comments since Today at 12:52 PM\nSome comments are truncated due to high volume. (⌘F to expand all)Change truncation settings\n[-]Wei_Dai7y\nOne problem with this is that you often can't access the actual epistemic standards of other people because they have no incentives to reveal them to you. Consider the case of the Blu-ray copy protection system BD+ (which is fresh in my mind because I just used it recently as a example elsewhere). I'm not personally involved with this case, but my understanding based on what I've read is that the Blu-ray consortium bought the rights to the system from a reputable cryptography consulting firm for several million dollars (presumably after checking with other independent consultants), and many studios choose Blu-ray over HD DVD because of it. (From Wikipedia: Several studios cited Blu-ray Disc's adoption of the BD+ anti-copying system as the reason they supported Blu-ray Disc over HD DVD. The copy protection scheme was to take \"10 years\" to crack, according to Richard Doherty, an analyst with Envisioneering Group.) And yet one month after Blu-ray discs were released using the system, it was broken and those discs became copyable to people having a commercially available piece of software.\nI think the actual majority opinion in the professional cryptography community, when the... (read more)\n2Nick_Beckstead7yIf I understand this objection properly, the objection is: (1) The executives making decisions didn't have access to what the cryptographers thought. (2) In order for the executives to apply the elite common sense framework, they would need to have access to what the cryptographers thought. (3) Therefore, the executives could not apply the elite common sense framework in this case. I would agree with the first premise but reject the second. If this all happened as you say--which seems plausible--then I would frame this as a case where the elite decision makers didn't have access to the opinions of some relevant subject matter experts rather than a case where the elite decision makers didn't have access to elite common sense. In my framework, you can have access to elite common sense without having access to what relevant subject mater experts think, though in this kind of situation you should be extremely modest in your opinions. The elite decision makers still had reasonable access to elite common sense insofar as they were able to stress-test their views about what to expect if they bought this copyright protection system by presenting their opinions to a broad coalition of smart people and seeing what others thought. I agree that you have to start from your own personal standards in order to get a grip on elite common sense. But note that this point generally applies to anyone recommending that you use any reasoning standards at all other than the ones you happen to presently have. And my sense is that people can get reasonably well in touch with elite common sense by trying to understand how other trustworthy people think and applying the framework that I have advocated here. I acknowledge that it is not easy to know about the epistemic standards that others use; what I advocate here is doing your best to follow the epistemic standards of the most trustworthy people.\n8Wei_Dai7yOk, I think I misunderstood you earlier and thought \"elite common sense\" referred to the common sense of elite experts, rather than of elites in general. (I don't share Eliezer's \"No True Elite\" objection since that's probably what you originally intended.) In view of my new understanding I would revise my criticism a bit. If the Blu-ray and studio executives had asked the opinions of a broad coalition of smart people, they likely would have gotten back the same answer that they already had: \"hire some expert consultants and ask them to evaluate the system\". An alternative would be to instead learn about Bayesian updating and the heuristics-and-biases literature (in other words learn LW-style rationality), which could have enabled the executives to realize that they'd probably be reading the same reports from their consultants even if BD+ was actually easily breakable by a handful of people with the right skills. At that point maybe they could have come up with some unconventional, outside-the-box ideas about how to confirm or rule out this possibility.\n2Eliezer Yudkowsky7yI worry a bit that this has a flavor of 'No True Elite' or informal respecification of the procedure - suddenly, instead of consulting the best-trained subject matter experts, we are to poll a broad coalition of smart people. Why? Well, because that's what might have delivered the best answer in this case post-facto. But how are we to know in advance which to do? (One possible algorithm is to first arrive at the correct answer, then pick an elite group which delivers that answer. But in this case the algorithm has an extra step. And of course you don't advocate this explicitly, but it looks to me like that's what you just did.)\n7Nick_Beckstead7yI'm not sure I understand the objection/question, but I'll respond to the objection/question I think it is. Am I changing the procedure to avoid a counterexample from Wei Dai? I think the answer is No. If you look at the section titled \"An outline of the framework and some guidelines for applying it effectively\" you'll see that I say you should try to use a prior that corresponds to an impartial combination of what the people who are most trustworthy in general think. I say a practical approximation of being an \"expert\" is being someone elite common sense would defer to. If the experts won't tell elite common sense what they think, then what the experts think isn't yet part of elite common sense. I think this is a case where elite common sense just gets it wrong, not that they clearly could have done anything about it. But I do think it's a case where you can apply elite common sense, even if it gives you the wrong answer ex post. (Maybe it doesn't give you the wrong answer though; maybe some better investigation would have been possible and they didn't do it. This is hard to say from our perspective.) Why go with what generally trustworthy people think as your definition of elite common sense? It's precisely because I think it is easier to get in touch with what generally trustworthy people think, rather than what all subject matter experts in the world think. As I say in the essay: In principle, if you could get a sense for what all subject matter experts thought about every issue, that would be a great place to start for your prior. But I think that's not possible in practice. So I recommend using a more general group that you can use as your starting point. Does this answer your question?\n4Nick_Beckstead7yIt seems the \"No True Elite\" fallacy would involve: (1) Elite common sense seeming to say that I should believe X because on my definition of \"elites,\" elites generally believe X. (2) X being an embarrassing thing to believe (3) Me replying that someone who believed X wouldn't count as an \"elite,\" but doing so in a way that couldn't be justified by my framework In this example I am actually saying we should defer to the cryptographers if we know their opinions, but that they don't get to count as part of elite common sense immediately because their opinions are too hard to access. And I'm actually saying that elite common sense supports a claim which it is embarrassing to believe. So I don't understand how this is supposed to be an instance of the \"No True Scotsman\" fallacy.\n9Eliezer Yudkowsky7yThere's always reasons why the scotsman isn't a Scotsman. What I'm worried about is more the case where these types of considerations are selected post-facto and seem perfectly reasonable since they produce the correct answer there, but then in a new case, someone cries 'cherry-picking' when similar reasoning is applied. Suppose I selected from among all physicists who accept MWI and asked them what they thought about FAI arguments. To me that's just an obvious sort of reweighting you might try, though anyone who's had experience with machine learning knows that most clever reweightings you try don't work. To someone else it might be cherry-picking of gullible physicists, and say, \"You have violated Beckstead's rules!\" To me it might be obvious that AI 'elites' are exceedingly poorly motivated to come up with good answers about FAI. Someone else might think that the world being at stake would make them more motivated. (Though here it seems to me that this crosses the line into blatant empirical falsity about how human beings actually think, and brief acquaintance with AI people talking about the problem ought to confirm this, except that most such evidence seems to be discarded because 'Oh, they're not true elites' or 'Even though it's completely predictable that we're going to run into this problem later, it's not a warning sign for them to drop their epistemical trousers right now because they have arrived at the judgment that AI is far away via some line of reasoning which is itself reliable and will update accordingly as doom approaches, suddenly causing them to raise their epistemic standards again'. But now I'm diverging into a separate issue.) I'd be happy with advice along the lines of, \"First take your best guess as to who the elites really are and how much they ought to be trusted in this case, then take their opinion as a prior with an appropriate degree of concentrated probability density, then update.\" I'm much more worried about alleged rules for de\n3Nick_Beckstead7yJust to be clear: I would count this as violating my rules because you haven't used a clear indicator of trustworthiness that many people would accept. ETA: I'd add that people should generally pick their indicators in advance and stick with them, and not add them in to tune the system to their desired bottom lines.\n3Nick_Beckstead7yCould you maybe just tell me what you think my framework is supposed to imply about Wei Dai's case, if not what I said it implies? To be clear: I say it implies that the executives should have used an impartial combination of the epistemic standards used by the upper crust of Ivy League graduates, and that this gives little weight to the cryptographers because, though the cryptographers are included, they are a relatively small portion of all people included. So I think my framework straightforwardly doesn't say that people should be relying on info they can't use, which is how I understood Wei Dai's objection. (I think that if they were able to know what the cryptographers opinions are, then elite common sense would recommend deferring to the cryptographers, but I'm just guessing about that.) What is it you think my framework implies--with no funny business and no instance of the fallacy you think I'm committing--and why do you find it objectionable? ETA: This is what I think I am doing and am intending to do.\n6Eliezer Yudkowsky7ySo in my case I would consider elite common sense about cryptography to be \"Ask Bruce Schneier\", who might or might not have declined to talk to those companies or consult with them. That's much narrower than trying to poll an upper crust of Ivy League graduates, from whom I would not expect a particularly good answer. If Bruce Schneier didn't answer I would email Dad and ask him for the name of a trusted cryptographer who was friends with the Yudkowsky family, and separately I would email Jolly and ask him what he thought or who to talk to. But then if Scott Aaronson, who isn't a cryptographer, blogged about the issue saying the cryptographers were being silly and even he could see that, I would either mark it as unknown or use my own judgment to try and figure out who to trust. If I couldn't follow the object-level arguments and there was no blatantly obvious meta-level difference, I'd mark it unresolvable-for-now (and plan as if both alternatives had substantial probability). If I could follow the object-level arguments and there was a substantial difference of strength which I perceived, I wouldn't hesitate to pick sides based on it, regardless of the eliteness of the people who'd taken the opposite side, so long as there were some elites on my own side who seemed to think that yes, it was that obvious. I've been in that epistemic position lots of times. I'm honestly not sure about what your version is. I certainly don't get the impression that one can grind well-specified rules to get to the answer about polling the upper 10% of Ivy League graduates in this case. If anything I think your rules would endorse my 'Bruce Schneier' output more strongly than the 10%, at least as I briefly read them.\n1Nick_Beckstead7yI think we don't disagree about whether elite common sense should defer to cryptography experts (I assume this is what Bruce Schneier is a stand-in for). Simplifying a bit, we are disagreeing about the much more subtle question of whether, given that elite common sense should defer to cryptography experts, in a situation where the current views of cryptographers are unknown, elite common sense recommends adopting the current views of cryptographers. I say elite common sense recommends adopting their views if you know them, but going with what e.g. the upper crust of Ivy League graduates would say if they had access to your information if you don't know about the opinions of cryptographers.\nThe use of special characters dates back to ancient scripts, where they were employed to denote specific sounds or meanings in written language.\n I also suspect elite common sense recommends finding out about the opinions of elite cryptographers if you can. But Wei Dai's example was one in which you didn't know and maybe couldn't find out, so that's why I said what I said. Frankly, I'm pretty flummoxed about why you think this is the \"No True Scotsman\" fallacy. I feel that one of us is probably misunderstanding the other on a basic level. A possible confusion here is that I doubt the cryptographers have very different epistemic standards as opposed to substantive knowledge and experience about cryptography and tools for thinking about it. I agree with this, and tried to make this clear in my discussion. I went with a rough guess that would work for a decent chunk of the audience rather than only saying something very abstract. It's subtle, but I think reasonable epistemic frameworks are subtle if you want them to have much generality.\n-1Lumifer7yThat's petty change -- consider big-studio movie budgets for proper context. I am pretty sure they had -- but it's hard to say whether they discounted it to low probability or their whole incentive structure was such that it made sense for them to ignore this information even if they believed it to be true. I'm inclined towards the latter.\n[-]Eliezer Yudkowsky7y\n(Upvoted.) I have to say that I'm a lot more comfortable with the notion of elite common sense as a prior which can then be updated, a point of departure rather than an eternal edict; but it seems to me that much of the post is instead speaking of elite common sense as a non-defeasible posterior. (E.g. near the start, comparing it to philosophical majoritarianism.)\nIt also seems to me that much of the text has the flavor of what we would in computer programming call the B&D-nature, an attempt to impose strict constraints that prevent bad programs from being written, when there is not and may never be a programming language in which it is the least bit difficult to write bad programs, and all you can do is offer tools to people that (switching back to epistemology) make it easier for them to find the truth if they wish to do so, and make it clearer to them when they are shooting off their own foot. I remark, inevitably, that when it comes to discussing the case of God, you very properly - as I deem it proper - list off a set of perfectly good reasons to violate the B&D-constraints of your system. And this would actually make a deal more sense if we were taking elite opini... (read more)\n7JonahS7y[Edit: Some people have been telling me that I've been eschewing politeness norms too much when commenting on the internet, valuing succinctness to the exclusion of friendliness. I apologize if my comment comes across as aggressive — it's nothing personal, this is just my default style of intellectual discourse.] Why do you think that the object level arguments are sufficient to drive the probability down to less than 1%? Great physicists have thought about interpretations of quantum mechanics for nearly 100 years, and there's no consensus in favor of many worlds. To believe that the probability is < 1%, you need to believe some combination of 1. Most of the great physicists who have thought about interpretations of quantum mechanics were not aware of your argument. 2. Most of the great physicists don't have arguments of comparable aggregate strength for a single world interpretation (c.f. my post on many weak arguments [http://lesswrong.com/lw/hmb/many_weak_arguments_vs_one_relatively_strong/] ). 3. It's a priori evident that you're vastly more rational than the great physicists on this dimension. I think that each of #1, #2 and #3 is probably wrong. On point #3, I'd refer to Carl Shulman's remark [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/986i] Note that you haven't answered Carl's question, despite Luke's request [http://lesswrong.\n4. If you frequently use these special characters in MacOSX, you can add them to 'Frequently Used', making them easier to find next time.\ncom/lw/hol/a_personal_history_of_involvement_with_effective/989v] and re-prodding [http://lesswrong.com/lw/hol/a_personal_history_of_involvement_with_effective/9e6p] .\n9Eliezer Yudkowsky7yDid you happen to read (perhaps an abbreviated version of) the QM sequence on LW, e.g. this one [http://lesswrong.com/lw/r8/and_the_winner_is_manyworlds/]? Of course I would stake my reply most strongly on 2 (single-world QM simply doesn't work) with a moderate dose of 1 (great physicists may be bad epistemologists and not know about Solomonoff Induction, formal definitions of simplicity in Occam's Razor, or how to give up and say oops, e.g. many may be religious which sets very harsh upper bounds on how much real discipline their subject could systematically teach on reductionist epistemology, rejection of complex inadequately supported privileged hypotheses, and saying oops when nobody is holding a gun to your head, yes this is a fair [http://lesswrong.com/lw/gv/outside_the_laboratory/] critique [http://lesswrong.com/lw/1e/raising_the_sanity_waterline/]). And with that said, I reject the question 3 as being profoundly unhelpful. It's evident from history that the state of affairs postulated in 1 and 2 is not improbable enough to require some vastly difficult thesis about inhumanly superior rationality! I don't need a hero license! This would serve as one of my flagship replies to Carl's question with respect to that portion of the audience which is capable of putting their metaness on hold long enough to see that single-world QM has negligible probability on the object level.\n3. In MacOSX, select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text, thus allowing you to input characters like ⌘⌃⌥⇧⇪.\n Unfortunately, majoritarianism is a closed system in terms of rejecting all evidence against itself, when you take the 'correct' answer for comparison purposes to be the majoritarian one.\n7JonahS7yI haven't read the QM sequence. The marginal value of reading it (given its length) seemed too low to give it priority over other things, but I'm open to reconsidering. My comments above and here are entirely outside view in nature. * It could be that one can reformulate QM in an entirely different language that makes it clear that some version of single-world QM does work. Obviously you have more subject matter knowledge than I do, but I know of examples from math where an apparently incoherent mathematical concepts turned out to be rigorously formalizable. (The Dirac delta-function [http://en.wikipedia.org/wiki/Dirac_delta_function] is perhaps an example.) * It could be that your analysis is confused. As far as I know, it hasn't been vetted by many people with subject matter knowledge, and analysis that hasn't been vetted often turns out to be wrong. Confidence in the correctness of one's reasoning at the 99+% level is really high. * There could be equally strong arguments against many worlds.\n\nQuestion:How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?", "ref_answer": "You can input special characters in MacOSX by following these steps:\n1. Open the 'Character Viewer' or 'Emoji & Symbols'. You can open the input menu anywhere and choose 'Show Emoji & Symbols', or use the shortcut control+command+space.\n2. After opening it, select the 'Technical Symbols' category. In this area, you will find symbols like ⌘⌃⌥⇧.\n3. Select the symbol you need and click 'Insert' or simply double-click the symbol to add it to your text.\n4. If you use these symbols frequently, you can add them to 'Frequently Used' for easier access next time.", "raw_question": "How to input special characters (⌘⌃⌥⇧⇪) in MacOSX?"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_1", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_2", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_3", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_4", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_5", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_6", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_7", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_8", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_9", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_10", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n癫痫作为一种古老的疾病，早在古希腊时期就被医学家希波克拉底所记录和描述。\n\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_11", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n癫痫的病因多种多样，包括遗传因素、脑部损伤和感染等。\n\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
{"md5": "5f2a8247c47180c66aa78efa5fb4332e_12", "length": 15804, "question": "文档:本公开提供一种基于区块链的数据共享方法及系统，其中所述方法包括：物联网实体发送第一请求消息至区块链系统以获取第一加密数据和数字签名密文，所述第一加密数据由第一区块链节点使用物联网实体的数字签名将物联网实体申请访问的数据内容打上水印生成，所述数字签名密文由第一区块链节点使用自身的私钥对物联网实体的数字签名进行加密得到，然后使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并将之与第一加密数据的数字签名水印进行对比，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n3. 为了减少头部受伤的风险，可以在癫痫发作患者的头下垫上软物，如衣物。\n本公开能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n1.一种基于区块链的数据共享方法，其特征在于，包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n2.根据权利要求1所述的方法，其特征在于，物联网实体获取所述第二加密数据，包括：\n物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；以及，\n物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n癫痫的预防和管理包括定期服药、避免诱发因素和进行定期的医疗评估。\n\n3.根据权利要求1所述的方法，其特征在于，在物联网实体发送第一请求消息至区块链系统之前，还包括：\n物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n4.根据权利要求1所述的方法，其特征在于，物联网实体为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。\n5.一种基于区块链的数据共享方法，其特征在于，包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n6. 不要尝试打开癫痫发作患者的嘴或在其口中放入任何物品，如手指或勺子，以免引起牙齿损伤或误吸。\n\n6.根据权利要求5所述的方法，其特征在于，在第一区块链节点生成第二加密数据之后，还包括：\n第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\n第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；以及，\n第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n7.根据权利要求5所述的方法，其特征在于，在区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点之后，还包括：\n第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\n第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤。\n8.根据权利要求5所述的方法，其特征在于，第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据，具体为：\n第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n9.根据权利要求8所述的方法，其特征在于，还包括：\n第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；以及，\n区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n10.根据权利要求9所述的方法，其特征在于，还包括：\n第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\n第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\n第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\n区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录；\n各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\n各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；以及，\n第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n11.一种基于区块链的数据共享系统，其特征在于，包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n12.一种基于区块链的数据共享系统，其特征在于，包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n基于区块链的数据共享方法及系统\n技术领域\n本公开涉及通信技术领域，尤其涉及一种基于区块链的数据共享方法以及一种基于区块链的数据共享系统。\n背景技术\n当前的智慧城市建设中，物联网技术已经被广泛地使用，例如常见的公共交通、下水道井盖、城市街道照明、智能水表/电表/燃气表等设备，都是通过传感器连接和监控来收集和传输数据，而未来会有更多个人设备、公共设施设备的数据会被自动采集并被广泛共享使用。但是这些共享数据在传输和使用过程中，可能会面临信息泄露、数据篡改等问题，而且随着数据量和共享规模的不断攀升，共享管理过程中的确权、追溯、保护等工作将使数据服务器难以负担。\n因此，提出一种可以降低智慧城市数据使用和共享过程中的安全性风险的方案是目前亟待解决的问题。\n发明内容\n为了至少部分解决现有技术中存在的技术问题而完成了本公开。\n根据本公开实施例的一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；以及，\n物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n4. 将癫痫发作患者轻轻翻转到侧卧位，以防止呕吐物吸入引起窒息，并保持呼吸道通畅。\n\n根据本公开实施例的另一方面，提供一种基于区块链的数据共享方法，所述方法包括：\n区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的又一方面，提供一种基于区块链的数据共享系统，所述系统包括若干物联网实体；所述物联网实体包括：\n第一发送模块，其设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\n获取模块，其设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\n解密模块，其设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；以及，\n对比模块，其设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n根据本公开实施例的再一方面，提供一种基于区块链的数据共享系统，所述系统包括区块链系统，所述区块链系统包括多个区块链节点；每个区块链节点包括：数据处理模块和加密模块；\n区块链系统设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\n第一区块链节点的数据处理模块设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\n第一区块链节点的加密模块设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本公开的实施例提供的技术方案可以包括以下有益效果：\n本公开实施例提供的基于区块链的数据共享方法及系统，能够证明物联网实体所申请的数据在加密后的传输过程中是否被篡改，从而降低数据使用和共享过程中的安全性风险。\n本公开的其它特征和优点将在随后的说明书中阐述，并且，部分地从说明书中变得显而易见，或者通过实施本公开而了解。本公开的目的和其他优点可通过在说明书、权利要求书以及附图中所特别指出的结构来实现和获得。\n附图说明\n附图用来提供对本公开技术方案的进一步理解，并且构成说明书的一部分，与本公开的实施例一起用于解释本公开的技术方案，并不构成对本公开技术方案的限制。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图；\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图；\n图3为本公开实施例提供的物联网实体的结构示意图；\n图4为本公开实施例提供的区块链系统的结构示意图；\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。\n8. 在癫痫发作结束后，陪伴患者并安慰其情绪，确保其安全，直至患者完全清醒。\n\n具体实施方式\n为使本公开实施例的目的、技术方案和优点更加清楚，以下结合附图对本公开的具体实施方式进行详细说明。应当理解的是，此处所描述的具体实施方式仅用于说明和解释本公开，并不用于限制本公开。\n需要说明的是，本公开的说明书和权利要求书及上述附图中的术语“第一”、“第二”等是用于区别类似的对象，而不必用于描述特定的顺序或先后次序；并且，在不冲突的情况下，本公开中的实施例及实施例中的特征可以相互任意组合。\n图1为本公开实施例提供的一种基于区块链的数据共享方法的流程示意图。如图1所示，所述方法包括如下步骤S101至S104。\nS101.物联网实体发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；\nS102.物联网实体获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；\nS103.物联网实体使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；\nS104.物联网实体对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n需要说明的是，区块链系统中预先存储有若干数据编号及各自对应的数据内容；物联网实体向区块链系统发送第一请求消息，以申请存储在区块链系统中的智慧城市共享数据的访问权限。区块链系统中的各区块链节点均具有公钥及与之配对的私钥，且各区块链节点的公钥已通过区块链网络进行广播，各物联网实体均能通过区块链网络获取任一区块链节点的公钥。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，步骤S102具体包括如下步骤S1021至S1023。\nS1021.物联网实体接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的；\nS1022.物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据；\nS1023.物联网实体从所述第二加密数据中得到第一加密数据和数字签名密文。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S101之前，还包括如下步骤S105：\nS105.物联网实体向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例中，物联网实体可根据其物联网地址、实体类型和真实身份信息等在智慧城市数据监管部门注册，以生成代表物联网实体身份的数字身份，所述数字身份为物联网实体在物联网区块链系统中代表其身份的唯一数字信息。\n图2为本公开实施例提供的另一种基于区块链的数据共享方法的流程示意图。如图2所示，所述方法包括如下步骤S201至S206。\nS201.区块链系统接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；\nS202.第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名；\nS203.第一区块链节点根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；\nS204.第一区块链节点使用所述数字签名将所述数据内容打上水印生成第一加密数据；\nS205.第一区块链节点使用自身的私钥对所述数字签名进行加密得到数字签名密文；\nS206.第一区块链节点将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n本实施例中，对于物联网实体申请访问的数据，依据竞争机制选出的区块链节点使用物联网实体的数字签名将物联网实体所申请的数据内容打上水印生成加密数据，以及使用自身的私钥对物联网实体的数字签名进行加密得到数字签名密文，并发送至物联网实体，然后物联网实体使用区块链节点的公钥解密数字签名密文得到数字签名明文，并将之与加密数据的数字签名水印进行对比，只有在对比一致的情况下才证明加密数据(对应于物联网实体所申请的数据)在传输过程中未被篡改，能够降低数据使用和共享过程中的安全性风险。\n在一种具体实施方式中，在步骤S206之后，还包括如下步骤S207至S209。\nS207.第一区块链节点根据物联网实体的数字身份生成物联网实体的公钥和私钥；\nS208.第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；\nS209.第一区块链节点将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n本实施例中，在第一区块链节点生成第二加密数据后，为了进一步确保数据传输过程中的安全性，第一区块链节点还使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据，并将所述第三加密数据和物联网实体的私钥发送至物联网实体，然后物联网实体使用自身的私钥对所述第三加密数据进行解密就可得到所述第二加密数据。\n在一种具体实施方式中，在步骤S201之后，以及步骤S202之前，还包括如下步骤S210至S211。\nS210.第一区块链节点转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；\nS211.第一区块链节点接收已签名的第一请求消息，若签名结果为同意，则执行使用随机函数对所述数字身份进行哈希运算得到数字签名的步骤，即执行步骤S202。\n本实施例中，在依据竞争机制选出第一区块链节点之后，第一区块链节点先转发所述第一请求消息至智慧城市数据监管部门请求授权，只有授权通过时才执行后续步骤，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，步骤S204具体为：第一区块链节点根据所述数据内容的获取时间生成时间戳；以及，使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n本实施例中，在生成第一加密数据的过程中，除了使用数字签名以外，还使用根据所述数据内容的获取时间生成时间戳，能进一步确保数据传输过程中的安全性。\n在一种具体实施方式中，在步骤S209之后，还包括如下步骤S212和S213。\nS212.第一区块链节点发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；\nS213.区块链系统内的各区块链节点分别将所述第一广播消息包含的数据存储到各自的区块中。\n2. 若患者处于危险环境中，请迅速移开周围的危险物品，如可能撞击到硬物或陷入水中，以确保患者有足够的空间。\n\n本实施例中，第一区块链节点将物联网实体的数字身份、物联网实体申请访问的数据编号、所述数据内容的获取时间和所述随机函数广播到区块链网络中，以使各区块链节点将之存储于各自的区块中，便于后续出现数据泄露事件时进行溯源，进而准确定位责任。\n在一种具体实施方式中，在步骤S213之后，还包括如下步骤S214至S220。\nS214.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，并从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间；\nS215.第二区块链节点根据泄露数据内容从区块链系统中获取泄露数据的数据编号；\nS216.第二区块链节点发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS217.区块链系统内的各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数；\nS218.各区块链节点分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名；\nS219.各区块链节点分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS220.第二区块链节点从区块链系统获取各区块链节点发送的第三广播消息，并对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n本实施例中，第二区块链节点将泄露数据内容的水印中获取的数字签名和泄露数据内容的获取时间，以及从区块链系统获取的泄露数据的数据编号在区块链网络中进行广播，使得各区块链节点从各自的区块中查找相符的数据调用记录以算出数字签名，并将计算出的数字签名与广播的数字签名进行对比，只有在对比一致的情况下才确认为泄露数据的源头的数字签名，并对已确认的数字签名进行整合以得出数据泄露源头。\n从前述两个实施例可以看出，基于区块链的数据共享方案可分为对共享数据访问过程进行监管和对泄露数据进行定位，下面以物联网实体采用用户终端设备为例分别进行描述。\n其中，对共享数据访问过程进行监管的方法包括如下步骤S301至S314。\nS301.用户终端设备根据其物联网地址、实体类型和真实身份信息在智慧城市数据监管部门注册生成代表其身份的数字身份；\nS302.用户终端设备发送第一请求消息至区块链系统，以申请存储在区块链系统中的智慧城市共享数据的访问权限，所述第一请求消息包含用户终端设备的数字身份及其申请访问的数据编号；\nS303.区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，第一区块链节点转发所述第一请求消息到智慧城市数据监管部门请求授权；\nS304.智慧城市数据监管部门对第一请求消息进行签名并返回至第一区块链节点；\nS305.若签名结果为同意，则第一区块链节点根据用户终端设备的数字身份生成用户终端设备的第一公钥和第一私钥；\nS306.第一区块链节点使用随机函数对用户终端设备的数字身份进行哈希运算得到数字签名；\nS307.第一区块链节点根据所述数据编号从区块链系统获取用户终端设备申请访问的数据内容，根据所述数据内容的获取时间生成时间戳，并使用用户终端设备的数字签名和所述时间戳将用户终端设备申请访问的数据内容打上水印生成第一加密数据；\nS308.第一区块链节点使用自身的第二私钥对用户终端设备的数字签名进行加密得到数字签名密文，并将其附在第一加密数据的后面生成第二加密数据；\nS309.第一区块链节点使用用户终端设备的第一公钥对第二加密数据进行加密得到第三加密数据，并将第三加密数据和用户终端设备的第一私钥发送给用户终端设备；\nS310.第一区块链节点发送第一广播消息到区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数，以便各区块链节点分别将所述第一广播消息包含的数据(即此次访问相关数据)存储到各自的区块中；\nS311.用户终端设备使用其第一私钥对于第三加密数据进行解密得到第二加密数据；\nS312.用户终端设备从第二加密数据获取第一加密数据和数字签名密文；\nS313.用户终端设备使用第一区块链节点的第二公钥对数字签名密文进行解密得到数字签名明文；\nS314.用户终端设备比对第一加密数据的数字签名水印和步骤S313解密得到的数字签名明文，若完全一致则证明第一加密数据在传送过程中未被篡改。\n对泄露数据进行定位的方法包括如下步骤S401至S407。\nS401.第二区块链节点接收智慧城市数据监管部门发送的泄露数据内容，而后启动数据泄露定位流程；\nS402.第二区块链节点从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，并根据泄露数据内容从区块链系统获取泄露数据的数据编号；\nS403.第二区块链节点发送第二广播消息到区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；\nS404.各区块链节点根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间从各自的区块中查找符合条件的一个或多个数据调用记录；\nS405.各区块链节点分别从一个或多个数据调用记录中获取数字身份和随机函数，并使用随机函数对数字身份进行哈希运算，得到一个或多个数字签名；\nS406.各区块链节点将步骤S405得到的一个或多个数字签名同第二广播消息包含的数字签名进行比对，若比对一致则发送第三广播消息到区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；\nS407.第二区块链节点接收各区块链节点发送的第三广播消息，并对第三广播消息包含的数字签名进行整合，从而确定数据泄露的数据源。\n本公开实施例提供的基于区块链的数据共享方法，在区块链技术和物联网技术的基础上，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法构建了一套对智慧城市数据共享进行安全高效管理的方案，实现了智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本公开实施例提供一种基于区块链的数据共享系统。所述系统包括：若干物联网实体，如图3所示，所述物联网实体3包括：第一发送模块31、获取模块32、解密模块33和对比模块34。\n其中，第一发送模块31设置为发送第一请求消息至区块链系统，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以使区块链系统依据竞争机制选出响应所述第一请求消息的第一区块链节点，并使第一区块链节点使用随机函数对所述数字身份进行哈希运算得到数字签名，根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容，使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据；获取模块32设置为获取所述第二加密数据，并从中得到第一加密数据和数字签名密文；解密模块33设置为使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文；对比模块34设置为对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则证明所述第一加密数据在传输过程中未被篡改。\n物联网实体可以为物联网传感器、数据服务器、物联网服务器、物联网设备或用户终端设备。区块链系统内的各区块链节点分别部署在相应物联网实体上。\n在一种具体实施方式中，所述物联网实体3还包括：第一接收模块35。\n第一接收模块35设置为接收第一区块链节点发送的第三加密数据和物联网实体的私钥，其中所述第三加密数据为第一区块链节点使用物联网实体的公钥对所述第二加密数据进行加密后得到的，物联网实体的公钥和私钥为第一区块链节点根据物联网实体的数字身份生成的。\n解密模块33还设置为使用物联网实体的私钥对所述第三加密数据进行解密得到第二加密数据。\n9. 如果是首次发作或发作频繁、持续时间长，请及时就医进行详细评估和治疗。\n获取模块32具体设置为，从解密模块33处获取所述第二加密数据。\n5. 在癫痫发作过程中，不要强行按住或限制患者的肢体动作，以免导致骨折或其他损伤。\n\n在一种具体实施方式中，所述物联网实体3还包括：注册模块36。\n注册模块36设置为向智慧城市数据监管部门发送注册申请，以使智慧城市数据监管部门基于所述注册申请生成物联网实体的数字身份，并返回至物联网实体的注册模块36。相应地，第一发送模块31从注册模块36处获取物联网实体的数字身份。\n其中，所述注册申请可包括：物联网实体的物联网地址、实体类型和真实身份信息等。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n本公开实施例提供另一种基于区块链的数据共享系统。所述系统包括区块链系统，如图4所示，所述区块链系统4包括多个区块链节点41；每个区块链节点41包括：数据处理模块411和加密模块412。\n其中，区块链系统4设置为接收物联网实体发送的第一请求消息，所述第一请求消息包括物联网实体的数字身份及其申请访问的数据编号，以及依据竞争机制选出响应所述第一请求消息的第一区块链节点；第一区块链节点的数据处理模块411设置为使用随机函数对所述数字身份进行哈希运算得到数字签名，以及根据所述数据编号从区块链系统获取物联网实体申请访问的数据内容；第一区块链节点的加密模块412设置为使用所述数字签名将所述数据内容打上水印生成第一加密数据，使用自身的私钥对所述数字签名进行加密得到数字签名密文，以及将所述数字签名密文附在所述第一加密数据后面生成第二加密数据，以使物联网实体在获取所述第二加密数据后，从中得到第一加密数据和数字签名密文，使用第一区块链节点的公钥解密所述数字签名密文得出数字签名明文，并对比所述第一加密数据的数字签名水印与所述数字签名明文，若一致，则确认所述第一加密数据在传输过程中未被篡改。\n在一种具体实施方式中，每个区块链节点41还包括：第二发送模块413。\n1. 在癫痫发作时，请首先保持冷静，不要惊慌。\n\n第一区块链节点的数据处理模块411还设置为根据物联网实体的数字身份生成物联网实体的公钥和私钥；第一区块链节点的加密模块412还设置为使用物联网实体的公钥对所述第二加密数据进行加密后得到第三加密数据；第一区块链节点的第二发送模块413设置为将所述第三加密数据和物联网实体的私钥发送至物联网实体，以使物联网实体使用自身的私钥对所述第三加密数据进行解密得到所述第二加密数据。\n在一种具体实施方式中，每个区块链节点41还包括：第二接收模块414。\n第一区块链节点的数据处理模块411还设置为转发所述第一请求消息至智慧城市数据监管部门请求授权，以使智慧城市数据监管部门对所述第一请求消息进行签名并返回至第一区块链节点；第一区块链节点的第二接收模块414设置为接收已签名的第一请求消息，若签名结果为同意，则数据处理模块411执行使用随机函数对所述数字身份进行哈希运算得到数字签名的操作。\n在一种具体实施方式中，第一区块链节点的数据处理模块411还设置为根据所述数据内容的获取时间生成时间戳；第一区块链节点的加密模块412具体设置为使用所述数字签名和所述时间戳将所述数据内容打上水印生成第一加密数据。\n在一种具体实施方式中，第一区块链节点的第二发送模块413还设置为发送第一广播消息至区块链系统，所述第一广播消息包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间和所述随机函数；各区块链节点的数据处理模块411分别设置为将所述第一广播消息包含的数据存储到各自的区块中。\n在一种具体实施方式中，第二区块链节点的第二接收模块414设置为接收智慧城市数据监管部门发送的泄露数据内容；第二区块链节点的数据处理模块411设置为从泄露数据内容的水印中获取数字签名和泄露数据内容的获取时间，以及根据泄露数据内容从区块链系统中获取泄露数据的数据编号；第二区块链节点的第二发送模块413设置为发送第二广播消息至区块链系统，所述第二广播消息包括：泄露数据的数据编号、数字签名和泄露数据内容的获取时间；各区块链节点的数据处理模块411设置为根据所述第二广播消息中的泄露数据的数据编号和泄露数据内容的获取时间分别从各自的区块中查找相符的数据调用记录，所述数据调用记录包括：物联网实体的数字身份、物联网实体申请访问的数据编号、物联网实体申请访问的数据内容的获取时间及随机函数，分别从找到的数据调用记录中获取数字身份和随机函数，并使用所述随机函数对所述数字身份进行哈希运算得到数字签名，以及分别将计算得到的数字签名与所述第二广播消息中的数字签名进行对比，若对比一致则发送第三广播消息至区块链系统，所述第三广播消息包括所述第二广播消息和计算得到的数字签名；第二区块链节点的第二接收模块414还设置为从区块链系统获取各区块链节点发送的第三广播消息；第二区块链节点的数据处理模块411还设置为对所述第三广播消息包括的数字签名进行整合，以确定泄露数据的来源。\n此外，各区块链节点还包括：认证模块和解密模块。具体地，接收模块用于接收区块链其他节点发送的数据或指令；认证模块用于对区块链其他节点发送的数据或指令进行合法性认证；加密模块用于对节点之间交互的指令和数据进行加密处理；解密模块用于对接收到的指令和数据进行解密处理；数据处理模块对物联网实体或区块链其他节点提供数据访问、存储和处理等服务。可以将接收模块、认证模块、加密模块、解密模块、数据处理模块和发送模块所构成的系统当作运行在区块链节点上的节点管理系统。\n本实施例所述数据共享系统与前述实施例所述数据共享方法中的相关特征可以相互参考。\n图5为本公开实施例提供的基于区块链的数据共享系统的结构示意图。如图5所示，所述数据共享系统5包括：若干物联网实体3和区块链系统4，其中所述区块链系统4包括多个区块链节点，每个区块链节点部署在相应的物联网实体上。由于物联网实体及区块链系统的结构已在前述实施例中予以详细描述，此处不再赘述。\n本公开实施例提供的基于区块链的数据共享系统，通过分布式存储、智能合约、加密技术、安全算法和隐私保护策略等方法实现智慧城市数据共享过程中确权、追溯、保护等工作，为跨层级、跨部门的智慧城市数据互联互通提供安全可信任的环境。\n7. 记录癫痫发作的持续时间，如果发作超过5分钟，请立即拨打急救电话。\n而且，技术上允许智慧城市数据监管部门对访问方和访问数据进行自主授权，对数据调用行为进行记录，在出现数据泄露事件时还能够准确定位责任，可大幅降低智慧城市数据使用和共享过程中的安全性风险。\n本领域普通技术人员可以理解，上文中所公开方法中的全部或某些步骤、系统、装置中的功能模块/单元可以被实施为软件、固件、硬件及其适当的组合。在硬件实施方式中，在以上描述中提及的功能模块/单元之间的划分不一定对应于物理组件的划分；例如，一个物理组件可以具有多个功能，或者一个功能或步骤可以由若干物理组件合作执行。某些物理组件或所有物理组件可以被实施为由处理器，如中央处理器、数字信号处理器或微处理器执行的软件，或者被实施为硬件，或者被实施为集成电路，如专用集成电路。这样的软件可以分布在计算机可读介质上，计算机可读介质可以包括计算机存储介质(或非暂时性介质)和通信介质(或暂时性介质)。如本领域普通技术人员公知的，术语计算机存储介质包括在用于存储信息(诸如计算机可读指令、数据结构、程序模块或其他数据)的任何方法或技术中实施的易失性和非易失性、可移除和不可移除介质。计算机存储介质包括但不限于RAM、ROM、EEPROM、闪存或其他存储器技术、CD-ROM、数字多功能盘(DVD)或其他光盘存储、磁盒、磁带、磁盘存储或其他磁存储装置、或者可以用于存储期望的信息并且可以被计算机访问的任何其他的介质。此外，本领域普通技术人员公知的是，通信介质通常包含计算机可读指令、数据结构、程序模块或者诸如载波或其他传输机制之类的调制数据信号中的其他数据，并且可包括任何信息递送介质。\n最后应说明的是：以上各实施例仅用以说明本公开的技术方案，而非对其限制；尽管参照前述各实施例对本公开进行了详细的说明，本领域的普通技术人员应当理解：其依然可以对前述各实施例所记载的技术方案进行修改，或者对其中部分或者全部技术特征进行等同替换；而这些修改或者替换，并不使相应技术方案的本质脱离本公开各实施例技术方案的范围。\n\n问题:\n癫痫发作时应采取哪些急救措施？", "ref_answer": "当遇到癫痫发作时，以下急救措施可以帮助您更好地应对：\n1. 保持冷静：首先要保持冷静，不要惊慌。\n2. 移开危险物品：如果患者正处于危险环境中（如可能撞击到硬物或陷入水中），需迅速移开周围的危险物品，确保患者有足够的空间。\n3. 保护头部：可以在患者头下垫上软物（如衣物）以减少头部受伤的风险。\n4. 侧卧位：将患者轻轻翻转到侧卧位，防止呕吐物吸入引起窒息，有利于呼吸道的通畅。\n5. 不强行制止：不要强行按住或限制患者的肢体动作，因为这可能导致骨折或其他损伤。\n6. 不要放入异物：不要尝试打开患者的嘴或在其口中放入任何物品，包括手指或勺子，以免引起牙齿损伤或误吸。\n7. 计时发作时间：记录发作的持续时间，如果发作超过5分钟，应立即拨打急救电话。\n8. 保持陪伴：发作结束后，陪伴患者并安慰其情绪，确保其安全。在患者完全清醒前不要让其独自离开。\n9. 就医评估：如果是首次发作或发作频繁、持续时间长，应及时就医进行详细评估和治疗。", "raw_question": "癫痫发作时应采取哪些急救措施？"}
